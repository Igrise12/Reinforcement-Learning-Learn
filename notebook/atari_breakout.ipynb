{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f00a2b9",
   "metadata": {},
   "source": [
    "### 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36f63c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "import os \n",
    "import ale_py\n",
    "from ale_py import ALEInterface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9460b44d",
   "metadata": {},
   "source": [
    "### 2. Test Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fe8be8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.11.2+ecc1138)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "gym.register_envs(ale_py)\n",
    "\n",
    "environment_name = 'Breakout-v4'\n",
    "env = gym.make(environment_name, render_mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44ddc466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]], shape=(210, 160, 3), dtype=uint8),\n",
       " {'lives': 5, 'episode_frame_number': 0, 'frame_number': 0})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864e2a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a0907a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0, 255, (210, 160, 3), uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b929900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:2.0\n",
      "Episode:2 Score:1.0\n",
      "Episode:3 Score:0.0\n",
      "Episode:4 Score:0.0\n",
      "Episode:5 Score:3.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 5 \n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    terminated = False\n",
    "    truncated = False\n",
    "\n",
    "    while not (terminated or truncated):\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        score += reward\n",
    "    print(f\"Episode:{episode} Score:{score}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bfa770",
   "metadata": {},
   "source": [
    "### 3. Vectorise Environement and Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feda0188",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_atari_env(environment_name, n_envs=4, seed=42)\n",
    "env = VecFrameStack(env, n_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f38dc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "log_path = os.path.join('..', 'Training', 'Logs', environment_name)\n",
    "model = A2C('CnnPolicy', env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d2a379e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ../Training/Logs/Breakout-v4/A2C_1\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 299      |\n",
      "|    ep_rew_mean        | 1.97     |\n",
      "| time/                 |          |\n",
      "|    fps                | 438      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.39    |\n",
      "|    explained_variance | 0.326    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -0.016   |\n",
      "|    value_loss         | 0.00265  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 282      |\n",
      "|    ep_rew_mean        | 1.63     |\n",
      "| time/                 |          |\n",
      "|    fps                | 434      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.38    |\n",
      "|    explained_variance | 0.178    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 0.171    |\n",
      "|    value_loss         | 0.183    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 276      |\n",
      "|    ep_rew_mean        | 1.47     |\n",
      "| time/                 |          |\n",
      "|    fps                | 436      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.35    |\n",
      "|    explained_variance | 0.875    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -0.0318  |\n",
      "|    value_loss         | 0.0403   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 293      |\n",
      "|    ep_rew_mean        | 1.78     |\n",
      "| time/                 |          |\n",
      "|    fps                | 443      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.28    |\n",
      "|    explained_variance | 0.969    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -0.0957  |\n",
      "|    value_loss         | 0.0178   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 303      |\n",
      "|    ep_rew_mean        | 1.97     |\n",
      "| time/                 |          |\n",
      "|    fps                | 446      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.21    |\n",
      "|    explained_variance | 0.857    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 0.118    |\n",
      "|    value_loss         | 0.0459   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 306      |\n",
      "|    ep_rew_mean        | 2.05     |\n",
      "| time/                 |          |\n",
      "|    fps                | 450      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.22    |\n",
      "|    explained_variance | 0.831    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -0.0602  |\n",
      "|    value_loss         | 0.0336   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 318      |\n",
      "|    ep_rew_mean        | 2.33     |\n",
      "| time/                 |          |\n",
      "|    fps                | 453      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.18    |\n",
      "|    explained_variance | 0.921    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -0.228   |\n",
      "|    value_loss         | 0.0389   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 323      |\n",
      "|    ep_rew_mean        | 2.45     |\n",
      "| time/                 |          |\n",
      "|    fps                | 455      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.29    |\n",
      "|    explained_variance | 0.736    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -0.132   |\n",
      "|    value_loss         | 0.0591   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 339      |\n",
      "|    ep_rew_mean        | 2.72     |\n",
      "| time/                 |          |\n",
      "|    fps                | 456      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.08    |\n",
      "|    explained_variance | -3.35    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -0.649   |\n",
      "|    value_loss         | 0.47     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 355      |\n",
      "|    ep_rew_mean        | 3.06     |\n",
      "| time/                 |          |\n",
      "|    fps                | 459      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.844   |\n",
      "|    explained_variance | 0.741    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 0.106    |\n",
      "|    value_loss         | 0.137    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 379      |\n",
      "|    ep_rew_mean        | 3.57     |\n",
      "| time/                 |          |\n",
      "|    fps                | 462      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.867   |\n",
      "|    explained_variance | 0.591    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 0.0788   |\n",
      "|    value_loss         | 0.0635   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 403      |\n",
      "|    ep_rew_mean        | 4.1      |\n",
      "| time/                 |          |\n",
      "|    fps                | 465      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.599   |\n",
      "|    explained_variance | 0.545    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -0.0439  |\n",
      "|    value_loss         | 0.146    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 434      |\n",
      "|    ep_rew_mean        | 4.81     |\n",
      "| time/                 |          |\n",
      "|    fps                | 467      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.686   |\n",
      "|    explained_variance | 0.502    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.0751   |\n",
      "|    value_loss         | 0.204    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 452      |\n",
      "|    ep_rew_mean        | 5.24     |\n",
      "| time/                 |          |\n",
      "|    fps                | 469      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.255   |\n",
      "|    explained_variance | 0.953    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -0.0182  |\n",
      "|    value_loss         | 0.0367   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 455      |\n",
      "|    ep_rew_mean        | 5.36     |\n",
      "| time/                 |          |\n",
      "|    fps                | 471      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.579   |\n",
      "|    explained_variance | 0.904    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -0.00311 |\n",
      "|    value_loss         | 0.027    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 455      |\n",
      "|    ep_rew_mean        | 5.35     |\n",
      "| time/                 |          |\n",
      "|    fps                | 472      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.564   |\n",
      "|    explained_variance | 0.734    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 0.0386   |\n",
      "|    value_loss         | 0.0736   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 443      |\n",
      "|    ep_rew_mean        | 5.08     |\n",
      "| time/                 |          |\n",
      "|    fps                | 472      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.167   |\n",
      "|    explained_variance | 0.706    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.0222   |\n",
      "|    value_loss         | 0.232    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 439      |\n",
      "|    ep_rew_mean        | 5        |\n",
      "| time/                 |          |\n",
      "|    fps                | 473      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.113   |\n",
      "|    explained_variance | 0.715    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 0.00921  |\n",
      "|    value_loss         | 0.0787   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 437      |\n",
      "|    ep_rew_mean        | 4.95     |\n",
      "| time/                 |          |\n",
      "|    fps                | 474      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.478   |\n",
      "|    explained_variance | 0.955    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -0.0531  |\n",
      "|    value_loss         | 0.0482   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 429      |\n",
      "|    ep_rew_mean        | 4.74     |\n",
      "| time/                 |          |\n",
      "|    fps                | 475      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0139  |\n",
      "|    explained_variance | 0.57     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -0.00115 |\n",
      "|    value_loss         | 0.264    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 426      |\n",
      "|    ep_rew_mean        | 4.62     |\n",
      "| time/                 |          |\n",
      "|    fps                | 476      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.325   |\n",
      "|    explained_variance | 0.916    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -0.0291  |\n",
      "|    value_loss         | 0.0498   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 434      |\n",
      "|    ep_rew_mean        | 4.9      |\n",
      "| time/                 |          |\n",
      "|    fps                | 477      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.377   |\n",
      "|    explained_variance | 0.75     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -0.243   |\n",
      "|    value_loss         | 0.24     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 438       |\n",
      "|    ep_rew_mean        | 5         |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 96        |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.064    |\n",
      "|    explained_variance | 0.524     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | -0.000757 |\n",
      "|    value_loss         | 0.175     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 453      |\n",
      "|    ep_rew_mean        | 5.34     |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.223   |\n",
      "|    explained_variance | 0.906    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -0.00213 |\n",
      "|    value_loss         | 0.0594   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 471      |\n",
      "|    ep_rew_mean        | 5.82     |\n",
      "| time/                 |          |\n",
      "|    fps                | 477      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.667   |\n",
      "|    explained_variance | 0.243    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -0.101   |\n",
      "|    value_loss         | 0.183    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 480      |\n",
      "|    ep_rew_mean        | 6.02     |\n",
      "| time/                 |          |\n",
      "|    fps                | 477      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.242   |\n",
      "|    explained_variance | 0.824    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -0.0186  |\n",
      "|    value_loss         | 0.202    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 496      |\n",
      "|    ep_rew_mean        | 6.31     |\n",
      "| time/                 |          |\n",
      "|    fps                | 477      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.294   |\n",
      "|    explained_variance | 0.977    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -0.0511  |\n",
      "|    value_loss         | 0.0163   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 496      |\n",
      "|    ep_rew_mean        | 6.31     |\n",
      "| time/                 |          |\n",
      "|    fps                | 477      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.309   |\n",
      "|    explained_variance | 0.818    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -0.229   |\n",
      "|    value_loss         | 0.138    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 501      |\n",
      "|    ep_rew_mean        | 6.37     |\n",
      "| time/                 |          |\n",
      "|    fps                | 477      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.431   |\n",
      "|    explained_variance | 0.588    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -0.0855  |\n",
      "|    value_loss         | 0.122    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 486      |\n",
      "|    ep_rew_mean        | 5.94     |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.303   |\n",
      "|    explained_variance | 0.799    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -0.0436  |\n",
      "|    value_loss         | 0.0749   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 495      |\n",
      "|    ep_rew_mean        | 6.18     |\n",
      "| time/                 |          |\n",
      "|    fps                | 478      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.229   |\n",
      "|    explained_variance | 0.822    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -0.0109  |\n",
      "|    value_loss         | 0.0798   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 496      |\n",
      "|    ep_rew_mean        | 6.19     |\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.361   |\n",
      "|    explained_variance | 0.801    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -0.155   |\n",
      "|    value_loss         | 0.123    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 498      |\n",
      "|    ep_rew_mean        | 6.14     |\n",
      "| time/                 |          |\n",
      "|    fps                | 480      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.25    |\n",
      "|    explained_variance | 0.635    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 0.00189  |\n",
      "|    value_loss         | 0.074    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 491      |\n",
      "|    ep_rew_mean        | 6.07     |\n",
      "| time/                 |          |\n",
      "|    fps                | 480      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.321   |\n",
      "|    explained_variance | 0.923    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 0.0363   |\n",
      "|    value_loss         | 0.0394   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 497      |\n",
      "|    ep_rew_mean        | 6.15     |\n",
      "| time/                 |          |\n",
      "|    fps                | 481      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.189   |\n",
      "|    explained_variance | 0.903    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 0.00302  |\n",
      "|    value_loss         | 0.0347   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 494      |\n",
      "|    ep_rew_mean        | 6.08     |\n",
      "| time/                 |          |\n",
      "|    fps                | 482      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.144   |\n",
      "|    explained_variance | 0.783    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 0.165    |\n",
      "|    value_loss         | 0.253    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 497      |\n",
      "|    ep_rew_mean        | 6.21     |\n",
      "| time/                 |          |\n",
      "|    fps                | 482      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.365   |\n",
      "|    explained_variance | 0.802    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 0.0509   |\n",
      "|    value_loss         | 0.055    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 502      |\n",
      "|    ep_rew_mean        | 6.35     |\n",
      "| time/                 |          |\n",
      "|    fps                | 483      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.161   |\n",
      "|    explained_variance | 0.606    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -0.0916  |\n",
      "|    value_loss         | 0.106    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 504      |\n",
      "|    ep_rew_mean        | 6.33     |\n",
      "| time/                 |          |\n",
      "|    fps                | 483      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.473   |\n",
      "|    explained_variance | 0.629    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 0.0838   |\n",
      "|    value_loss         | 0.0965   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 510      |\n",
      "|    ep_rew_mean        | 6.44     |\n",
      "| time/                 |          |\n",
      "|    fps                | 484      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.278   |\n",
      "|    explained_variance | 0.945    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 0.00263  |\n",
      "|    value_loss         | 0.0951   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 520      |\n",
      "|    ep_rew_mean        | 6.65     |\n",
      "| time/                 |          |\n",
      "|    fps                | 485      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0951  |\n",
      "|    explained_variance | 0.845    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -0.0207  |\n",
      "|    value_loss         | 0.111    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 495      |\n",
      "|    ep_rew_mean        | 6.1      |\n",
      "| time/                 |          |\n",
      "|    fps                | 485      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.317   |\n",
      "|    explained_variance | 0.952    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 0.0437   |\n",
      "|    value_loss         | 0.0309   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 484      |\n",
      "|    ep_rew_mean        | 5.89     |\n",
      "| time/                 |          |\n",
      "|    fps                | 485      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 177      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.149   |\n",
      "|    explained_variance | 0.895    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 0.00147  |\n",
      "|    value_loss         | 0.125    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 484      |\n",
      "|    ep_rew_mean        | 5.9      |\n",
      "| time/                 |          |\n",
      "|    fps                | 486      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 181      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.2     |\n",
      "|    explained_variance | 0.894    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -0.0315  |\n",
      "|    value_loss         | 0.0502   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 498      |\n",
      "|    ep_rew_mean        | 6.22     |\n",
      "| time/                 |          |\n",
      "|    fps                | 486      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.21    |\n",
      "|    explained_variance | 0.847    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 0.0165   |\n",
      "|    value_loss         | 0.0345   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 503      |\n",
      "|    ep_rew_mean        | 6.28     |\n",
      "| time/                 |          |\n",
      "|    fps                | 487      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.103   |\n",
      "|    explained_variance | 0.794    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 0.00651  |\n",
      "|    value_loss         | 0.0546   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 509      |\n",
      "|    ep_rew_mean        | 6.43     |\n",
      "| time/                 |          |\n",
      "|    fps                | 487      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.104   |\n",
      "|    explained_variance | 0.735    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -0.00811 |\n",
      "|    value_loss         | 0.062    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 526      |\n",
      "|    ep_rew_mean        | 6.81     |\n",
      "| time/                 |          |\n",
      "|    fps                | 487      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0386  |\n",
      "|    explained_variance | 0.93     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -0.0309  |\n",
      "|    value_loss         | 0.193    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 533      |\n",
      "|    ep_rew_mean        | 6.96     |\n",
      "| time/                 |          |\n",
      "|    fps                | 488      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 200      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0401  |\n",
      "|    explained_variance | 0.706    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 0.00107  |\n",
      "|    value_loss         | 0.111    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 544      |\n",
      "|    ep_rew_mean        | 7.23     |\n",
      "| time/                 |          |\n",
      "|    fps                | 488      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 204      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.179   |\n",
      "|    explained_variance | 0.977    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -0.0171  |\n",
      "|    value_loss         | 0.0351   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x7fccc99c38e0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551d8465",
   "metadata": {},
   "source": [
    "### 4. Save and Reload Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86f72f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../Training/Saved Models/Breakout-v4/A2C_Breakout_Model'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2c_path = os.path.join('..', 'Training', 'Saved Models', environment_name, 'A2C_Breakout_Model')\n",
    "a2c_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c15a10ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igrise/Project Coding/Reinforcement Learning Projects/gymnasium_learn/.venv/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:284: UserWarning: Path '../Training/Saved Models/Breakout-v4' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    }
   ],
   "source": [
    "model.save(a2c_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35396849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model = A2C.load(a2c_path, env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b472a7",
   "metadata": {},
   "source": [
    "### 5. Evaluate and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4ce917d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]]]], shape=(4, 84, 84, 4), dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02edff98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(7.6), np.float64(2.0591260281974))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = make_atari_env(environment_name, n_envs=1)\n",
    "env = VecFrameStack(env, n_stack=4)\n",
    "\n",
    "\n",
    "\n",
    "evaluate_policy(model, env, n_eval_episodes = 10, render = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b66a10a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m action, _states \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(obs, deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \n\u001b[1;32m      5\u001b[0m obs, rewards, dones, info \u001b[38;5;241m=\u001b[39m vec_env\u001b[38;5;241m.\u001b[39mstep(action) \n\u001b[0;32m----> 6\u001b[0m \u001b[43mvec_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhuman\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Project Coding/Reinforcement Learning Projects/gymnasium_learn/.venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:405\u001b[0m, in \u001b[0;36mVecEnvWrapper.render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m, mode: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[np\u001b[38;5;241m.\u001b[39mndarray]:\n\u001b[0;32m--> 405\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvenv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Project Coding/Reinforcement Learning Projects/gymnasium_learn/.venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:405\u001b[0m, in \u001b[0;36mVecEnvWrapper.render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m, mode: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[np\u001b[38;5;241m.\u001b[39mndarray]:\n\u001b[0;32m--> 405\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvenv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Project Coding/Reinforcement Learning Projects/gymnasium_learn/.venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:104\u001b[0m, in \u001b[0;36mDummyVecEnv.render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m, mode: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[np\u001b[38;5;241m.\u001b[39mndarray]:\n\u001b[1;32m     98\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    Gym environment rendering. If there are multiple environments then\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    they are tiled together in one image via ``BaseVecEnv.render()``.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    :param mode: The rendering type.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Project Coding/Reinforcement Learning Projects/gymnasium_learn/.venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:280\u001b[0m, in \u001b[0;36mVecEnv.render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m    279\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvecenv\u001b[39m\u001b[38;5;124m\"\u001b[39m, bigimg[:, :, ::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 280\u001b[0m     \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bigimg\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vec_env = model.get_env() \n",
    "obs = vec_env.reset()\n",
    "for i in range(1000):\n",
    "    action, _states = model.predict(obs, deterministic=True) \n",
    "    obs, rewards, dones, info = vec_env.step(action) \n",
    "    vec_env.render(\"human\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6a098c",
   "metadata": {},
   "source": [
    "### 6. Tes in gymnasium Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f3f1c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 1. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[1. 0. 1. 0.]\n",
      "[0. 0. 0. 1.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 1. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[1. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 1. 0.]\n",
      "[0. 0. 0. 1.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 1. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[1. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 1.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[1. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 1. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "Episode:1 Score:[4. 3. 3. 3.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 1. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "Episode:2 Score:[0. 1. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 1.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "Episode:3 Score:[0. 0. 0. 1.]\n",
      "[0. 0. 1. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "Episode:4 Score:[0. 0. 1. 0.]\n",
      "[0. 1. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 1.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 1. 0.]\n",
      "[1. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 1.]\n",
      "[0. 1. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[1. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 1.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 1. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 1. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[1. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 1.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 1. 0. 0.]\n",
      "[1. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 0.]\n",
      "Episode:5 Score:[4. 4. 2. 4.]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "vec_env = model.get_env() \n",
    "obs = vec_env.reset()\n",
    "episodes = 5 \n",
    "for episode in range(1, episodes+1):\n",
    "    done = False\n",
    "    score = 0 \n",
    "\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        obs, rewards, dones, info = vec_env.step(action)\n",
    "        print(rewards)\n",
    "        score += rewards\n",
    "        vec_env.render(\"human\")\n",
    "        time.sleep(0.003)\n",
    "        done = dones[0]\n",
    "    print(f\"Episode:{episode} Score:{score}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff5f39a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277c64dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gymnasium_learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
